{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Example data/example.txt', 'r') as f:\n",
    "    text_example = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 300,\n",
    "    chunk_overlap = 20,\n",
    "    separators = ['\\n\\n', '\\n']\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_text(text_example)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 year old male\n",
      "\n",
      "Notes:\n",
      "1. Emergency Department medical note 1/1/25\n",
      "8 year old boy\n",
      "NKDA \n",
      "No medications\n",
      "Last meal 8:00am\n",
      "\n",
      "Developed right sided testicular pain 1/7 ago. Did not tell anybody as did not want to worry anyone.\n",
      "Ate a sandwich on the way to hospital at 0730.\n",
      "USS showing avascular right testes - referred to surgeons at PCH\n",
      "------\n",
      "O/E\n",
      "Comfortable\n",
      "Not examined further\n",
      "\n",
      "Plan\n",
      "Admit to hospital\n",
      "NBM\n",
      "Surgeons informed \n",
      "\n",
      "2. Surgical note 1/1/25\n",
      "Paediatric Surgery Admission\n",
      "8M with right testicular torsion on ultrasound\n",
      "HPC\n",
      "One day history of right sided scrotal pain\n",
      "Initially had vomiting but none in past 6h\n",
      "No fevers\n",
      "No urinary symptoms\n",
      "No abdominal pain\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "print(chunks[i])\n",
    "\n",
    "print(\"------\")\n",
    "\n",
    "print(chunks[i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/rebel-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/rebel-large\")\n",
    "gen_kwargs = {\n",
    "    \"max_length\": 256,\n",
    "    \"length_penalty\": 0,\n",
    "    \"num_beams\": 20,\n",
    "    \"num_return_sequences\": 20,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction triplets sentence 0\n",
      "[{'head': 'NBM', 'type': 'subclass of', 'tail': 'O/E'}]\n",
      "Prediction triplets sentence 1\n",
      "[{'head': 'NBM', 'type': 'has part', 'tail': 'E'}]\n",
      "Prediction triplets sentence 2\n",
      "[{'head': 'NBM', 'type': 'subclass of', 'tail': 'E'}]\n",
      "Prediction triplets sentence 3\n",
      "[{'head': 'NBM', 'type': 'has part', 'tail': 'O/E'}]\n",
      "Prediction triplets sentence 4\n",
      "[{'head': 'NBM', 'type': 'facet of', 'tail': 'O/E'}]\n",
      "Prediction triplets sentence 5\n",
      "[{'head': 'NBM', 'type': 'has part', 'tail': 'O'}]\n",
      "Prediction triplets sentence 6\n",
      "[{'head': 'NBM', 'type': 'studied by', 'tail': 'Physician'}]\n",
      "Prediction triplets sentence 7\n",
      "[{'head': 'O/E', 'type': 'studied by', 'tail': 'Physician'}]\n",
      "Prediction triplets sentence 8\n",
      "[{'head': 'O/E', 'type': 'different from', 'tail': 'BMI'}, {'head': 'BMI', 'type': 'different from', 'tail': 'O/E'}]\n",
      "Prediction triplets sentence 9\n",
      "[{'head': 'O/E', 'type': 'different from', 'tail': 'NBM'}, {'head': 'NBM', 'type': 'different from', 'tail': 'O/E'}]\n",
      "Prediction triplets sentence 10\n",
      "[{'head': 'NBM', 'type': 'instance of', 'tail': 'O/E'}]\n",
      "Prediction triplets sentence 11\n",
      "[{'head': 'NBM', 'type': 'part of', 'tail': 'E'}]\n",
      "Prediction triplets sentence 12\n",
      "[{'head': 'NBM', 'type': 'part of', 'tail': 'O/E'}]\n",
      "Prediction triplets sentence 13\n",
      "[{'head': 'Neurosurgeons informed', 'type': 'part of', 'tail': 'NHS'}]\n",
      "Prediction triplets sentence 14\n",
      "[{'head': 'NBM', 'type': 'subclass of', 'tail': 'Observable'}]\n",
      "Prediction triplets sentence 15\n",
      "[{'head': 'NBM', 'type': 'subclass of', 'tail': 'O'}]\n",
      "Prediction triplets sentence 16\n",
      "[{'head': 'NHS', 'type': 'located in the administrative territorial entity', 'tail': 'England'}]\n",
      "Prediction triplets sentence 17\n",
      "[{'head': 'Neuropathy', 'type': 'subclass of', 'tail': 'Neuropathy'}]\n",
      "Prediction triplets sentence 18\n",
      "[{'head': 'O/E', 'type': 'different from', 'tail': 'NBM'}]\n",
      "Prediction triplets sentence 19\n",
      "[{'head': 'NBM', 'type': 'has part', 'tail': 'O'}, {'head': 'NBM', 'type': 'has part', 'tail': 'E'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "def extract_triplets(text):\n",
    "    triplets = []\n",
    "    relation, subject, relation, object_ = '', '', '', ''\n",
    "    text = text.strip()\n",
    "    current = 'x'\n",
    "    for token in text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").split():\n",
    "        if token == \"<triplet>\":\n",
    "            current = 't'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "                relation = ''\n",
    "            subject = ''\n",
    "        elif token == \"<subj>\":\n",
    "            current = 's'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "            object_ = ''\n",
    "        elif token == \"<obj>\":\n",
    "            current = 'o'\n",
    "            relation = ''\n",
    "        else:\n",
    "            if current == 't':\n",
    "                subject += ' ' + token\n",
    "            elif current == 's':\n",
    "                object_ += ' ' + token\n",
    "            elif current == 'o':\n",
    "                relation += ' ' + token\n",
    "    if subject != '' and relation != '' and object_ != '':\n",
    "        triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "    return triplets\n",
    "\n",
    "# Text to extract triplets from\n",
    "text = 'Punta Cana is a resort town in the municipality of Higüey, in La Altagracia Province, the easternmost province of the Dominican Republic.'\n",
    "text = chunks[4]\n",
    "\n",
    "# Tokenizer text\n",
    "model_inputs = tokenizer(text, max_length=256, padding=True, truncation=True, return_tensors = 'pt')\n",
    "\n",
    "# Generate\n",
    "generated_tokens = model.generate(\n",
    "    model_inputs[\"input_ids\"].to(model.device),\n",
    "    attention_mask=model_inputs[\"attention_mask\"].to(model.device),\n",
    "    **gen_kwargs,\n",
    ")\n",
    "\n",
    "# Extract text\n",
    "decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=False)\n",
    "\n",
    "# Extract triplets\n",
    "for idx, sentence in enumerate(decoded_preds):\n",
    "    print(f'Prediction triplets sentence {idx}')\n",
    "    print(extract_triplets(sentence))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O/E\n",
      "Comfortable\n",
      "Not examined further\n",
      "\n",
      "Plan\n",
      "Admit to hospital\n",
      "NBM\n",
      "Surgeons informed\n"
     ]
    }
   ],
   "source": [
    "print(chunks[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  7.47s/it]\n"
     ]
    }
   ],
   "source": [
    "# model_name = 'meta-llama/Meta-Llama-3.1-8B'\n",
    "\n",
    "model_name = 'meta-llama/llama-2-7b-chat-hf'\n",
    "\n",
    "# model_name = 'victorlxh/ICKG-v2.0'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",  # puts model on GPU if available\n",
    "    torch_dtype=\"auto\"  # uses correct precision automatically\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the given context, the following are the relationships that can be inferred:\n",
      "\n",
      "1. John (subject) lives in (relationship) US (object)\n",
      "2. Eifel towel (subject) is located in (relationship) Paris (object)\n",
      "3. Hayao Miyazaki (subject) is (relationship) Japanese animator (object)\n",
      "4. Developed (subject) right sided testicular pain (relationship) 1/7 ago (object)\n",
      "5. Ate (subject) a sandwich (relationship) on the way to hospital (object) at 0730\n",
      "6. USS (subject) showing avascular right testes (relationship) referred to surgeons (object) at PCH\n",
      "7. Comfortable (subject) (relationship) Not examined further (object)\n",
      "8. Admit (subject) to hospital (relationship) (object)\n",
      "9. Surgeons (subject) informed (relationship) (object)\n",
      "\n",
      "Therefore, the list of JSON objects is:\n",
      "\n",
      "[\n",
      "{\n",
      "\"subject\": \"Developed\",\n",
      "\"relationship\": \"developed\",\n",
      "\"object\": \"right sided testicular pain\"\n",
      "},\n",
      "{\n",
      "\"subject\": \"Ate\",\n",
      "\"relationship\": \"ate\",\n",
      "\"object\": \"sandwich\"\n",
      "},\n",
      "{\n",
      "\"subject\": \"USS\",\n",
      "\"relationship\": \"showing\",\n",
      "\"object\": \"avascular right testes\"\n",
      "},\n",
      "{\n",
      "\"subject\": \"Surgeons\",\n",
      "\"relationship\": \"informed\",\n",
      "\"object\": \"at PCH\"\n",
      "},\n",
      "{\n",
      "\"subject\": \"Comfortable\",\n",
      "\"relationship\": \"comfortable\",\n",
      "\"object\": \"Not examined further\"\n",
      "},\n",
      "{\n",
      "\"subject\": \"Admit\",\n",
      "\"relationship\": \"admit\",\n",
      "\"object\": \"to hospital\"\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        #\"content\": \"Return a list of named entities in the text.\"\n",
    "        #\"content\": \"You are an AI assistant for a hospital that looks to construct meaningful triples of knoweldege in JSON output (entity, relationship, entity).\",\n",
    "        'content': \"\"\"Extract all the relationships based on the given context. \n",
    "Return a list of JSON objects. For example:\n",
    "\n",
    "<Examples>\n",
    "    [{{\"subject\": \"John\", \"relationship\": \"lives in\", \"object\": \"US\"}},\n",
    "    {{\"subject\": \"Eifel towel\", \"relationship\": \"is located in\", \"object\": \"Paris\"}},\n",
    "    {{\"subject\": \"Hayao Miyazaki\", \"relationship\": \"is\", \"object\": \"Japanese animator\"}}]\n",
    "</Examples>\n",
    "\n",
    "- ONLY return triples and nothing else. None of 'subject', 'relationship' and 'object' can be empty.\n",
    "\"\"\"\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": f\"Context: {chunks[2]}\\n\\nTriples:\"},\n",
    "]\n",
    "model_inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "input_length = model_inputs.shape[1]\n",
    "generated_ids = model.generate(model_inputs, do_sample=True, max_new_tokens=1000)\n",
    "print(tokenizer.batch_decode(generated_ids[:, input_length:], skip_special_tokens=True)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Developed right sided testicular pain 1/7 ago. Did not tell anybody as did not want to worry anyone.\n",
      "Ate a sandwich on the way to hospital at 0730.\n",
      "USS showing avascular right testes - referred to surgeons at PCH\n",
      "\n",
      "O/E\n",
      "Comfortable\n",
      "Not examined further\n",
      "\n",
      "Plan\n",
      "Admit to hospital\n",
      "NBM\n",
      "Surgeons informed\n"
     ]
    }
   ],
   "source": [
    "print(chunks[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[...]\n",
      "Patient is a 8 year old male who presented with right sided testicular pain.\n",
      "Ultrasound showed right sided testicular torsion.\n",
      "Patient underwent right sided scrotal\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Extract Triples: {text}\"\"\"\n",
    "model_inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
    "input_length = model_inputs.input_ids.shape[1]\n",
    "generated_ids = model.generate(**model_inputs, max_new_tokens=50)\n",
    "print(tokenizer.batch_decode(generated_ids[:, input_length:], skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
